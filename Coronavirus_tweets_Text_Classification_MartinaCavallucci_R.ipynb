{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Coronavirus tweets-Text Classification-MartinaCavallucci.R.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "R",
      "name": "ir"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJfOVJGWz_XP"
      },
      "source": [
        "# **Coronavirus tweets-Text Classification**\n",
        "\n",
        "#### Autore: Martina Cavallucci\n",
        "#### Email: nome.cognome@studio.unibo.it\n",
        "#### Release: Gennaio, 2020\n",
        "\n",
        "*Questo script R esegue un' analisi e una classificazione di testi di tweet durante il perodo di Marzo 2019 e Aprile 2019.\n",
        "Tali tweet si riferiscono ad un topic specifico: Covid-19.\n",
        "L'obiettivo Ã¨ quindi comprendere le relazioni tra i termini utilizzati, e la classificazione dei tweet rispetto al sentiment (Positive, Negative, Neutral).*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjTyI4yi1Dwd"
      },
      "source": [
        "---\n",
        "\n",
        "#### Import delle librerie R e di Text Mining\n",
        "##### This operation take a few minutes\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nwh1UhZ6fZ22"
      },
      "source": [
        "install.packages(\"RWeka\")\n",
        "install.packages(\"data.table\") \n",
        "install.packages(\"checkmate\")\n",
        "install.packages(\"stringr\") \n",
        "install.packages(\"caret\") \n",
        "install.packages(\"quanteda\") \n",
        "install.packages(\"quanteda.textmodels\")\n",
        "install.packages('e1071', dependencies=TRUE)\n",
        "library(data.table)\n",
        "library(RWeka)\n",
        "library(tidyverse)\n",
        "if(!require(\"R.utils\"))\n",
        "  install.packages(\"R.utils\")\n",
        "library(\"R.utils\")\n",
        "library(checkmate)\n",
        "library(stringr)\n",
        "library(caret)\n",
        "library(quanteda)\n",
        "library(quanteda.textmodels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AudtbAjk1VPO"
      },
      "source": [
        "---\n",
        "\n",
        "#### Import del text set su Github\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eJElWchhgXaW"
      },
      "source": [
        "download.file('https://github.com/CavallucciMartina/Coronavirus-tweets-Text-Classification/blob/main/input/Corona_NLP_test.csv.gz?raw=true', 'test.csv.gz') #, method=\"curl\")\n",
        "gunzip('test.csv.gz')\n",
        "download.file('https://github.com/CavallucciMartina/Coronavirus-tweets-Text-Classification/blob/main/input/Corona_NLP_train.csv.gz?raw=true', 'train.csv.gz') #, method=\"curl\")\n",
        "gunzip('train.csv.gz')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89Qmpxqp1brW"
      },
      "source": [
        "---\n",
        "\n",
        "#### Prima visualizzazione del train set\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FU3zLbcBhod-"
      },
      "source": [
        "train <- read.csv(\"train.csv\")\n",
        "test <- read.csv(\"test.csv\")\n",
        "head(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84pLjEnC1gfk"
      },
      "source": [
        "---\n",
        "\n",
        "#### Dimensioni del train set e del test set\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UgRR_35zjkUF"
      },
      "source": [
        "dim(train)\n",
        "dim(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYGGp5jY1zlo"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "#### Preparazione analisi risultati di Sentiment in Train\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hnRRC1o6rllq"
      },
      "source": [
        "library(tidyverse)\n",
        "districtSentiment = count(train,Sentiment)\n",
        "districtSentiment[,c(2)]\n",
        "districtSentiment"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSXDGdpB9vnk"
      },
      "source": [
        "---\n",
        "\n",
        "#### Grafico delle percentuali di sentiment nel train set\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVyH0Yy1tiET"
      },
      "source": [
        "#jpeg(\"PieChartSentiment.jpg\")\n",
        "sentiment <- c(districtSentiment[,c(2)]) \n",
        "lbls <- c('Positive','Negative','Neutral','Extremely Positive','Extremely Negative')\n",
        "pct <- round(sentiment/sum(sentiment)*100)\n",
        "lbls <- paste(lbls, pct) # add percents to labels\n",
        "lbls <- paste(lbls,\"%\",sep=\"\") # ad % to labels\n",
        "pie(sentiment,labels = lbls, col=rainbow(length(lbls)),\n",
        "   main=\"Pie Chart of sentiment\") \n",
        "#dev.off()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTKe5blsvUTt"
      },
      "source": [
        "---\n",
        "\n",
        "#### Preparazione train per classificazione; trasformazione da 5 classi a 3: Positive, Negative, Neutral\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZI1k08TzCeW"
      },
      "source": [
        "new_train = data.frame(\n",
        "                text = train$OriginalTweet,\n",
        "                labels = train$Sentiment,\n",
        "                stringsAsFactors=F)\n",
        "\n",
        "new_test = data.frame(\n",
        "                text = test$OriginalTweet,\n",
        "                labels = test$Sentiment,\n",
        "                stringsAsFactors=F)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQZnc_jbaZqs"
      },
      "source": [
        "rm(train)\n",
        "rm(test)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WxDMG-T0NEz"
      },
      "source": [
        "# Data has 5 classes, let's convert them to 3\n",
        "\n",
        "classes_def <- function(x)\n",
        "    if (x ==  \"Extremely Positive\"){\n",
        "         \"2\"\n",
        "    }else if( x == \"Extremely Negative\"){\n",
        "         \"0\"\n",
        "    }else if(x == \"Negative\"){\n",
        "         \"0\"\n",
        "    }else if(x ==  \"Positive\"){\n",
        "         \"2\"\n",
        "    }else {\n",
        "         \"1\"\n",
        "    }\n",
        "\n",
        "\n",
        "new_train$labels = lapply(new_train$labels, function(x) classes_def(x))\n",
        "new_test$labels = lapply(new_test$labels, function(x) classes_def(x))\n",
        "\n",
        "districtSentiment = count(new_train,labels)\n",
        "districtSentiment[,c(2)]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEzvBji6wKqC"
      },
      "source": [
        "---\n",
        "\n",
        "#### Creazione del corpus\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxB1JreDy6EL"
      },
      "source": [
        "mycorpus <- corpus(new_train)\n",
        "\n",
        "# Assigns a unique identifier to each text\n",
        "docvars(mycorpus, \"Textno\") <-\n",
        "  sprintf(\"%02d\", 1:ndoc(mycorpus)) \n",
        "\n",
        "mycorpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fckhz62pL43T"
      },
      "source": [
        "# Save statistics in \"mycorpus.stats\"\n",
        "mycorpus.stats <- summary(mycorpus)\n",
        "\n",
        "# And print the statistics of the first 10 observations\n",
        "head(mycorpus.stats, n = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61nTKQHw17X2"
      },
      "source": [
        "head(kwic(mycorpus, \"covid19\", window=4),10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x89qQwB2LJy"
      },
      "source": [
        "head(kwic(mycorpus, \"work\", window=4),10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3E4NyttFxnO2"
      },
      "source": [
        "head(kwic(mycorpus, \"food\", window=4),10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZ2dEmnsOkqa"
      },
      "source": [
        "---\n",
        "\n",
        "#### Text-preprocessing\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5pKUaZr0rud"
      },
      "source": [
        "head(mycorpus,3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNo1VkzEMSKT"
      },
      "source": [
        "# Preprocess the text\n",
        "\n",
        "# Create tokens\n",
        "token <-\n",
        "  tokens(\n",
        "    mycorpus,\n",
        "    remove_numbers = TRUE,\n",
        "    remove_punct = TRUE,\n",
        "    remove_symbols = TRUE,\n",
        "    remove_url = TRUE,\n",
        "    split_hyphens = TRUE,\n",
        "    include_docvars = TRUE\n",
        "  )\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYzGGWbMyzVm"
      },
      "source": [
        "head(token,20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dJczHD-Muxi"
      },
      "source": [
        "# Clean tokens \n",
        "token_ungd <- tokens_select(\n",
        "  token,\n",
        "  c(\"(http|https)://([^\\\\s]+)\", \"<.*?>\",\"#\\\\w+\",\"@\\\\w+\",\"\\\\s+\"),\n",
        "  selection = \"remove\",\n",
        "  valuetype = \"regex\",\n",
        "  verbose = TRUE\n",
        ")\n",
        "toks_nostop <- tokens_select(token_ungd, pattern = stopwords(\"en\"), selection = \"remove\")\n",
        "print(toks_nostop)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_43FiAaeT4h"
      },
      "source": [
        "rm(mycorpus)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybCq2Bo0OZjF"
      },
      "source": [
        "---\n",
        "\n",
        "#### Creazione matrice documenti-termini\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAl-8lOm21D1"
      },
      "source": [
        "doc_term_matrix <- dfm(toks_nostop,\n",
        "                       tolower = TRUE,\n",
        "                       stem = FALSE)\n",
        "\n",
        "doc_term_matrix2 <- dfm_tfidf(doc_term_matrix)\n",
        "doc_term_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgY4VvvmalNo"
      },
      "source": [
        "rm(new_train)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfSE6mSeO-40"
      },
      "source": [
        "doc_term_matrix.trim <-doc_term_matrix\n",
        "doc_term_matrix.trim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBxCVZzPaoVe"
      },
      "source": [
        "rm(doc_term_matrix)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8EK2_7rVPXh5"
      },
      "source": [
        "# And print the results of the first 10 observations and first 10 features in a DFM\n",
        "head(dfm_sort(doc_term_matrix.trim, decreasing = TRUE, margin = \"both\"),\n",
        "     n = 10,\n",
        "     nf = 10) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tw6AnHoXOVdA"
      },
      "source": [
        "---\n",
        "\n",
        "#### Generazione wordcloud\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIro3XdwGnq1"
      },
      "source": [
        "# jpeg(\"wordcloud.jpeg\")\n",
        "set.seed(100)\n",
        "textplot_wordcloud(doc_term_matrix, min_count = 100, random_order = FALSE,\n",
        "                   rotation = .25, \n",
        "                   color = RColorBrewer::brewer.pal(8,\"Dark2\"))\n",
        "# dev.off()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVTIQNuULzre"
      },
      "source": [
        "dict <- featnames(doc_term_matrix)\n",
        "dict"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQU0_ItUOahx"
      },
      "source": [
        "---\n",
        "\n",
        "## **Classificazione**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5PCbequTKko"
      },
      "source": [
        "Supervised machine learning - Naive Bayes (NB) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpQ_t_8-Wlq-"
      },
      "source": [
        "#Cleaning test set\n",
        "test_corpus <- corpus(new_test)\n",
        "token <-\n",
        "  tokens(\n",
        "    test_corpus,\n",
        "    remove_numbers = TRUE,\n",
        "    remove_punct = TRUE,\n",
        "    remove_symbols = TRUE,\n",
        "    remove_twitter = TRUE,\n",
        "    remove_url = TRUE,\n",
        "    remove_hyphens = TRUE,\n",
        "    include_docvars = TRUE\n",
        "  )\n",
        "# Clean tokens \n",
        "token_ungd <- tokens_select(\n",
        "  token,\n",
        "  c(\"[\\\\d-]\", \"(http|https)://([^\\\\s]+)\", \"<.*?>\",\"#\\\\w+\",\"@\\\\w+\",\"\\\\d+\",\"\\\\s+\"),\n",
        "  selection = \"remove\",\n",
        "  valuetype = \"regex\",\n",
        "  verbose = TRUE\n",
        ")\n",
        "toks_nostop <- tokens_select(token_ungd, pattern = stopwords(\"en\"), selection = \"remove\")\n",
        "dfmat_test <- dfm(token_ungd,\n",
        "                       tolower = TRUE,\n",
        "                       stem = FALSE,\n",
        "                       remove = stopwords(\"english\"))\n",
        "dfmat_test <- dfm_tfidf(dfmat_test)\n",
        "dfmat_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZrNJND8asxh"
      },
      "source": [
        "rm(new_test)\n",
        "rm(test_corpus)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWa4ir3wYQQE"
      },
      "source": [
        "# Train naive Bayes\n",
        "# The function takes a DFM as the first argument \n",
        "tmod_nb <- textmodel_nb(doc_term_matrix.trim, unlist(docvars(doc_term_matrix.trim, \"labels\")), distribution = c(\"multinomial\"))\n",
        "summary(tmod_nb)\n",
        "# The prior indicates an assumed distribution. \n",
        "# Here we choose how frequently the categories occur in our data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0W-Ti2sEaRMH"
      },
      "source": [
        "summary(tmod_nb)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWN5v53LaR4s"
      },
      "source": [
        "dfmat_matched <- dfm_match(dfmat_test, features = featnames(doc_term_matrix.trim))"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqydgnsmacnV"
      },
      "source": [
        "actual_class <- unlist(dfmat_matched$labels)\n",
        "predicted_class <- predict(tmod_nb, newdata = dfmat_matched,force = TRUE)\n",
        "tab_class <- table(actual_class, predicted_class)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u5k2Ub9T95IC"
      },
      "source": [
        "confusionMatrix(tab_class, mode = \"everything\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DV3lTZssORhn"
      },
      "source": [
        "# Train naive Bayes\n",
        "# The function takes a DFM as the first argument \n",
        "tmod_nb <- textmodel_nb(doc_term_matrix.trim, unlist(docvars(doc_term_matrix.trim, \"labels\")), distribution = c(\"Bernoulli\"))\n",
        "summary(tmod_nb)\n",
        "# The prior indicates an assumed distribution. \n",
        "# Here we choose how frequently the categories occur in our data\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iV1DAKKOXl4"
      },
      "source": [
        "dfmat_matched <- dfm_match(dfmat_test, features = featnames(doc_term_matrix.trim))\n",
        "actual_class <- unlist(dfmat_matched$labels)\n",
        "predicted_class <- predict(tmod_nb, newdata = dfmat_matched,force = TRUE)\n",
        "tab_class <- table(actual_class, predicted_class)\n",
        "confusionMatrix(tab_class, mode = \"everything\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DWl8G9aL27Gv"
      },
      "source": [
        "Linear SVM classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87v3XvyJ0sh3"
      },
      "source": [
        "# # tmod <- textmodel_svm(doc_term_matrix.trim, unlist(quanteda::docvars(doc_term_matrix.trim, \"labels\")))\n",
        "tmod <- textmodel_svm(doc_term_matrix.trim, y = quanteda::docvars(doc_term_matrix.trim, \"labels\"))\n",
        "predict(tmod)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12SZvthH-nPc"
      },
      "source": [
        "# dfmat_matched <- dfm_match(dfmat_test, features = featnames(doc_term_matrix.trim))\n",
        "# actual_class <- unlist(dfmat_matched$labels)\n",
        "# predicted_class <- predict(tmod, newdata = dfmat_matched,force = TRUE)\n",
        "# tab_class2 <- table(actual_class, predicted_class)\n",
        "# tab_class2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6KMFD21-1Jc"
      },
      "source": [
        "# confusionMatrix(tab_class2, mode = \"everything\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3n3xaW1pVOvx"
      },
      "source": [
        "#Random Forest\n",
        "library(randomForest)\n",
        "RF_model = randomForest(labels ~ ., data=doc_term_matrix.trim, n_estimators=100, max_depth=5, random_state=0)\n",
        "predictRF = predict(RF_model, newdata=dfmat_test)\n",
        "table(dfmat_test$labels, predictRF)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkxKgDHB6DbH"
      },
      "source": [
        "Random forest Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MUHYL-F4rANR"
      },
      "source": [
        "TODO \n",
        "- Classificatore Random Forest\n",
        "- Classificatore K-NN\n",
        "- Classificatore Rocchio\n",
        "- CLassificatore Multinomial Bayesian (sempre con nb)\n",
        "- LSTM bidirectional\n",
        "\n",
        "\n",
        "Provare anche classificazione con bigram"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWehe1zUV8qs"
      },
      "source": [
        "# the installation of required packages takes about 5 minutes\n",
        "if(!require(\"reticulate\"))\n",
        "  install.packages(\"reticulate\")#, dependencies=TRUE)\n",
        "library(reticulate)\n",
        "\n",
        "if(!require(\"text2vec\"))\n",
        "  install.packages(\"text2vec\")#, dependencies=TRUE)\n",
        "library(text2vec)\n",
        "\n",
        "if(!require(\"devtools\"))\n",
        "  install.packages(\"devtools\")#, dependencies=TRUE)\n",
        "library(devtools)\n",
        "\n",
        "if(!require(\"keras\")){\n",
        "  devtools::install_github(\"rstudio/keras\")\n",
        "#  library(reticulate)\n",
        "#  library(keras)\n",
        "#  install_keras(version =\"2.1.5\", tensorflow=\"1.4.1-gpu\") # instead of last version you can use a previous one like \"1.2.1-gpu\"\n",
        "}\n",
        "\n",
        "\n",
        "if(!require(\"iterators\"))\n",
        "  install.packages(\"iterators\")#, dependencies=TRUE)\n",
        "library(iterators)\n",
        "\n",
        "\n",
        "if(!require(\"yaml\"))\n",
        "  install.packages(\"yaml\")#, dependencies=TRUE)\n",
        "library(yaml)\n",
        "\n",
        "\n",
        "if(!require(\"foreach\"))\n",
        "  install.packages(\"foreach\")#, dependencies=TRUE)\n",
        "library(foreach)\n",
        "\n",
        "if(!require(\"R.utils\"))\n",
        "  install.packages(\"R.utils\")\n",
        "library(\"R.utils\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gysXFNLlWNaP"
      },
      "source": [
        "\n",
        "length(dict)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}